{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3x3zSYPaY9vU"
   },
   "source": [
    "# Pytorch Introduction\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m12sl/dl-hse-2020/blob/master/02-mechanics/pytorch%20train%20loop.ipynb)\n",
    "\n",
    "В этой тетрадке мы напишем познакомимся с базовыми возможностями pytorch.\n",
    "\n",
    "**Цели тетрадки**\n",
    "\n",
    "1. Познакомиться с типами данных и арифметикой в pytorch.\n",
    "1. Научиться пользоваться автоматическим дифференцированием.\n",
    "1. Попробовать low-level и high-level API на нескольких задачах.\n",
    "\n",
    "\n",
    "\n",
    "**План работы**\n",
    "\n",
    "1. Познакомиться на примерах с pytorch API.\n",
    "1. Научиться получать градиенты для переменных.\n",
    "1. Реализовать линейную регрессию на pytorch.\n",
    "1. Натренировать классификатор FashionMNIST с помощью high-level API.\n",
    "1. Зафайнтюнить предобученную модель из пакета torchvision.\n",
    "\n",
    "\n",
    "## Материалы по pytorch:\n",
    "\n",
    "+ https://pytorch.org/resources/\n",
    "+ https://pytorch.org/docs/stable/index.html\n",
    "+ ходить по исходникам с помощью IDE\n",
    "+ [Классная статья про pytorch internal](http://blog.ezyang.com/2019/05/pytorch-internals/)\n",
    "\n",
    "\n",
    "## Важные модули:\n",
    "\n",
    "- `autograd` -- функции для вычисления производных\n",
    "- `nn`-- классы для слоев и моделей\n",
    "- `nn.functional` -- функциональный API для некоторых операций\n",
    "- `nn.init` -- различные варианты инциализации\n",
    "- `optim` -- оптимизаторы\n",
    "- `utils.data` -- API для работы с данными (Dataset & DataLoader)\n",
    "\n",
    "\n",
    "**Дополнительные пакеты:**\n",
    "- `torchvision` -- предобученные модели, преобразования картинок и датасеты\n",
    "- `torchaudio` -- датасеты и полезные преобразования\n",
    "- `torchtext` -- датасеты и полезные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# install requirements\n",
    "! pip install torchviz torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSIb8PLGY9vZ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output  # потребуется для перерисовки графиков\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchviz  # потребуется для отображения графов\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основа вычислений: torch.Tensor\n",
    "\n",
    "\n",
    "Это практически `numpy.ndarray` с некоторыми дополнительными возможностями.\n",
    "\n",
    "Официальная документация: https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "\n",
    "**Важные поля:**\n",
    "- `.device` -- `cuda` или `cpu`\n",
    "- `.dtype` -- более строгие правила приведения типов, чем в numpy\n",
    "- `.requires_grad` -- флаг говорит, должен ли автоград вычислять градиенты для этой переменной\n",
    "- `.data` -- содержимое переменной\n",
    "- `.grad` -- градиенты, сохраненные для этой переменной\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1547404548924,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "pe29HnAKY9vd",
    "outputId": "fcca8236-f309-421d-e87c-d6fbf063f8d5"
   },
   "outputs": [],
   "source": [
    "# numpy world\n",
    "x = np.arange(16).astype(np.float32).reshape(4, 4)\n",
    "\n",
    "print(\"X :\\n %s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", np.dot(x, x.T))\n",
    "print(\"mean over cols :\\n%s\" % (x.mean(axis=-1)))\n",
    "print(\"cumsum of cols :\\n%s\" % (np.cumsum(x, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 673,
     "status": "ok",
     "timestamp": 1547404555089,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "mFmEwrWQY9wl",
    "outputId": "0fbde5e5-8fed-4515-a7f3-b4f87a29a31d"
   },
   "outputs": [],
   "source": [
    "# pytorch world\n",
    "x = torch.arange(16).float().view(4, 4)\n",
    "\n",
    "print(\"X :\\n%s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", torch.matmul(x, x.transpose(1, 0)))\n",
    "print(\"mean over cols :\\n\", torch.mean(x, dim=-1))\n",
    "print(\"cumsum of cols :\\n\", torch.cumsum(x, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzYCigYxY9wt"
   },
   "source": [
    "Numpy и Pytorch не требуют описания статического графа вычислений.\n",
    "Результат получается сразу при выполнении.\n",
    "\n",
    "Можно отлаживаться с помощью pdb/ipdb или просто print.\n",
    "\n",
    "API несколько различается:\n",
    "\n",
    "|        numpy        |      pytorch    |\n",
    "|:-------             |         -------:|\n",
    "| `x.reshape([1,2,8])`| `x.view(1,2,8)` |\n",
    "| `x.sum(axis=-1)`    | `x.sum(dim=-1)` |\n",
    "| `x.astype('int64')` | `x.type(torch.int64)` |\n",
    "\n",
    "\n",
    "Легко конвертировать между собой:\n",
    "\n",
    "```python\n",
    "torch.from_numpy(npx) # -- вернет Tensor\n",
    "tt.numpy() # -- вернет Numpy Array\n",
    "```\n",
    "\n",
    "Преобразовать тензор из одного числа в обычное питоновское число:\n",
    "```python\n",
    "torch.tensor([1]).item() # 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычислительный граф\n",
    "\n",
    "Вычислительный граф строится по выражениям, в которых участвует `torch.tensor`.\n",
    "\n",
    "Все вершины в графе можно разбить на два класса: Leaf (листовые) и Non-Leaf (не листовые) вершины. \n",
    "\n",
    "Если тензор не зависит от других, он является листовой вершиной.\n",
    "\n",
    "Для оптимизации памяти, pytorch будет считать градиенты только для _листовых_ переменных с выставленным флагом `requires_grad=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4.], requires_grad=True)  # leaf tensor\n",
    "alpha = torch.tensor([-1.0, ]) # leaf, but without grads\n",
    "y = x + 1  # not a leaf variable\n",
    "z = x * y * alpha\n",
    "print(z)\n",
    "\n",
    "\n",
    "torchviz.make_dot(z, {\"input x\": x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4.], requires_grad=True)  # leaf tensor\n",
    "alpha = torch.tensor([-1.0, ]) # leaf, but without grads\n",
    "y = x + 1  # not a leaf variable\n",
    "loss = (alpha * y).mean()\n",
    "\n",
    "print(\"BEFORE BACKWARD\")\n",
    "[print(f\"var: {var}\\ngrad: {var.grad}\\n\") for var in [x, y, alpha]]\n",
    "\n",
    "loss.backward()\n",
    "print(\"\\nAFTER BACKWARD:\")\n",
    "[print(f\"var: {var}\\ngrad: {var.grad}\\n\") for var in [x, y, alpha]]\n",
    "\n",
    "    \n",
    "# просто так повторно запросить .backward() нельзя, попробуйте раскомментить:\n",
    "# loss.backward()\n",
    "\n",
    "# но можно сделать еще один тензор (зависящий от предыдущих переменных) и запросить .backward() в нем:\n",
    "# loss2 = (alpha * y).mean()\n",
    "# loss2.backward()\n",
    "\n",
    "# print(\"\\nAFTER BACKWARD2:\")\n",
    "# [print(f\"var: {var}\\ngrad: {var.grad}\\n\") for var in [x, y, alpha]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, как пользоваться автоматическим дифференцированием:\n",
    "\n",
    "1. Создать переменную: `a = torch.tensor(..., requires_grad=True)`\n",
    "\n",
    "2. Определить какую-нибудь дифференцируемую функцию `loss = whatever(a)`\n",
    "\n",
    "3. Запросить обратный проход `loss.backward()`\n",
    "\n",
    "4. Градиенты будут доступны в `a.grad`\n",
    "\n",
    "5. При повторных вызовах `.backward()` (у разных лоссов) градиенты в задействованных переменных суммируются. Это позволяет использовать несколько функций ошибок или виртуально увеличивать `batch_size`. Поэтому, перед каждый вычислением градиентов, стоит обнулять старые градиенты.\n",
    "\n",
    "**NB: вычисление градиентов работает только для тензоров с вещественным типом данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 491,
     "status": "error",
     "timestamp": 1547405637406,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "r3rKaDeHkCDx",
    "outputId": "4a826849-c57c-49e2-c2fc-56a81fcc676b"
   },
   "outputs": [],
   "source": [
    "# will not work\n",
    "x = torch.tensor([1, 2, 3, 4], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MB2E0HXc0YQ5"
   },
   "source": [
    "Чтобы выключить автоматическое вычисление градиентов, есть три возможности:\n",
    "- выставить `requires_grad=False`\n",
    "- использовать контекст-менеджер `with torch.no_grad()`\n",
    "- применить `detach`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1547410105269,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "0whd_wGr0Xlg",
    "outputId": "bc502448-c324-4f72-83dd-89f8966af73f"
   },
   "outputs": [],
   "source": [
    "t = torch.tensor([1.0, 0.5])\n",
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y = x**2\n",
    "print(t.requires_grad)\n",
    "print(x.requires_grad)\n",
    "print(y.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.exp(x)\n",
    "    print(z.requires_grad)\n",
    "    \n",
    "# detach from the graph\n",
    "w = torch.log(x).detach()\n",
    "print(w.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocw1MsBIkLYh"
   },
   "source": [
    "# Линейная регрессия\n",
    "\n",
    "Рассмотрим пример линейной регрессии на датасете Boston. \n",
    "\n",
    "Для простоты оставим одну компонету признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 715,
     "status": "ok",
     "timestamp": 1547406896812,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "X34atyS5Y9xA",
    "outputId": "8e34a964-ce17-4a8d-fc77-04389e80dee2"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "X, Y = load_boston(return_X_y=True)\n",
    "print(X.shape)\n",
    "X = X[:, -1] / X[:, -1].std()\n",
    "Y = Y / Y.std()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X, Y)\n",
    "plt.ylabel(\"target\")\n",
    "plt.xlabel(\"feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно провести прямую линию, минимизирующую MSE.\n",
    "Запишем вычислительный граф и получим градиенты для одного шага градиентного спуска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1547406897141,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "QGfIe-HzY9xJ",
    "outputId": "a1742d23-2223-4bc4-c7dd-3eba8dabf135"
   },
   "outputs": [],
   "source": [
    "# model tensors\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# data tensors\n",
    "x = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(Y).type(torch.float)\n",
    "\n",
    "y_pred = w * x + b\n",
    "loss = torch.mean((y_pred - y)**2)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "#now w.grad is a tensor containing gradient of L w.r.t. w\n",
    "print(\"dL/dw = \\n\", w.grad)\n",
    "print(\"dL/db = \\n\", b.grad)\n",
    "\n",
    "\n",
    "torchviz.make_dot(loss, {\"Weight: W\": w, \"Weight: b\": b})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lEn3f-9QY9xc"
   },
   "source": [
    "Предлагается реализовать обучение модели линейной регрессии.\n",
    "\n",
    "**(0.1 балла)** Напишите код для обновления весов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1547407342686,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "g3wj6u71Y9xe",
    "outputId": "e216320b-001a-4438-d9cb-c855928e214a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(Y).type(torch.float)\n",
    "\n",
    "for i in range(100):    \n",
    "    # напишите шаг градиентного спуска\n",
    "    <your code>\n",
    "    \n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "    # the rest of code is just bells and whistles\n",
    "    if (i + 1) % 5==0:\n",
    "        #draw linear regression prediction vs data\n",
    "        clear_output(True)\n",
    "        plt.axhline(0, color='gray')\n",
    "        plt.axvline(0, color='gray')\n",
    "        plt.scatter(x.numpy(),y.numpy())\n",
    "        plt.plot(x.numpy(),y_pred.data.numpy(),color='orange')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.item())\n",
    "        if loss.item() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYR7GonVY9xm"
   },
   "source": [
    "# Optimizers\n",
    "\n",
    "В этом примере мы пользовались простым правилом для градиентного спуска:\n",
    "  \n",
    "$$\\theta^{n+1} = \\theta^{n} - \\alpha \\nabla_{\\theta}L$$\n",
    "\n",
    "\n",
    "Единственным параметром в нем является $\\alpha$ -- это `learning_rate`.\n",
    "\n",
    "На практике часто используют различные модификации (например _Momentum_):\n",
    "\n",
    "$$\\theta^{n+1} = \\theta^{n} - U^{n}\\\\\n",
    "U^{n} = \\gamma U^{n-1} + \\alpha \\nabla_{\\theta}(L)\n",
    "$$\n",
    "\n",
    "Хороший обзор алгоритмов оптимизации для сетей можно посмотреть [тут](http://ruder.io/optimizing-gradient-descent/).\n",
    "\n",
    "\n",
    "\n",
    "Pytorch предоставляет практически все широкораспространненные оптимизаторы:    \n",
    "http://pytorch.org/docs/master/optim.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Оптимизаторы очень просто использовать:\n",
    "\n",
    "- при создании оптимизатора требуется указать список переменных, с которыми он будет работать\n",
    "- `opt.zero_grad()` сбрасывает градиенты\n",
    "- `opt.step()` применяет `update` ($U^{n}$) к весам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1547407528989,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "m_Sdf5aQY9xn",
    "outputId": "5d17921d-add1-48ff-b8a7-7b2f5ba63780"
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "x = torch.from_numpy(X).type(torch.float)\n",
    "y = torch.from_numpy(Y).type(torch.float)\n",
    "# model tensors\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# define optimizer\n",
    "opt = torch.optim.RMSprop([w, b], lr=0.1)\n",
    "\n",
    "for i in range(100):\n",
    "    # compute loss\n",
    "    y_pred = w * x  + b\n",
    "    loss = torch.mean((y_pred - y) ** 2)\n",
    "    \n",
    "    # backprop and gradient descent\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    \n",
    "    #the rest of code is just bells and whistles\n",
    "    if (i + 1) % 5 == 0:\n",
    "        #draw linear regression prediction vs data\n",
    "        clear_output(True)\n",
    "        plt.axhline(0, color='gray')\n",
    "        plt.axvline(0, color='gray')\n",
    "        plt.scatter(x.numpy(), y.numpy())\n",
    "        plt.plot(x.numpy(), y_pred.data.numpy(), color='orange')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.item())\n",
    "        if loss.item() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "KeVrAA6LY9xu"
   },
   "source": [
    "## Highlevel-API \n",
    "\n",
    "При работе с нейронными сетями становится неудобно контролировать переменные с весами по-отдельности. \n",
    "Pytorch предоставляет высокоуровневый API для моделей: [nn.Module](http://pytorch.org/docs/master/nn.html#torch.nn.Module)\n",
    "\n",
    "Чтобы воспользоваться моделью необходимо отнаследоваться от `torch.nn.Module`, определить слои и описать `forward`. \n",
    "\n",
    "`backward` будет вычислен автоматически."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher-level API:\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels=784, hidden_size=40):\n",
    "        super(Net, self).__init__()\n",
    "        # here you construct weights for layers\n",
    "        self.fc1 = nn.Linear(784, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # here you describe usage of layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "    # backward function computes automaticaly\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net(torch.rand(3, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простую цепочку слоев удобно заворачивать в `nn.Sequential`.\n",
    "В таком случае не придется писать `.forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(784, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 10),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "net(torch.rand(32, 784)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве датасета возьмем FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3821,
     "status": "ok",
     "timestamp": 1547407542987,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "MAJhDSN8Y9xv",
    "outputId": "cfab66d1-1193-4835-f0bd-a591357e385b"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda t: t.reshape(-1))]  # let's convert image (28, 28) to vector (784)\n",
    ")\n",
    "train_dataset = FashionMNIST(\"./tmp\", train=True, download=True, transform=default_transform)\n",
    "test_dataset = FashionMNIST(\"./tmp\", train=False, download=True, transform=default_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=32)\n",
    "\n",
    "train_dataset[0][0].shape\n",
    "plt.figure(figsize=[6, 6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.title(\"Label: %i\" % train_dataset[i][1])\n",
    "    plt.imshow(train_dataset[i][0].reshape(28, 28), cmap='gray')  # don't forget convert vector to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7y6TCrdxY9xz"
   },
   "source": [
    "**(0.1 балла)** Напишите код для тренировки.\n",
    "Предлагается для треккинга экспериментов использовать [`defaultdict`](https://docs.python.org/3.3/library/collections.html#defaultdict-objects)\n",
    "\n",
    "**NB: обязательно доставайте числа из тензоров, не сохраняйте тензора с каждой итерации в какой-нибудь буффер.\n",
    "Каждый тензор тащит за собой информацию для построения графа, это ест память**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1547407669131,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "cAH1muhlY9x2",
    "outputId": "a517cc92-0163-4f98-d2a8-a5f1cc9d0425"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader):\n",
    "    model.train()\n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        # todo: your code here        \n",
    "        <your code>\n",
    "        # у вас должно быть две скалярных переменных: с метрикой (acc) и лоссом (loss)\n",
    "        logs['acc'].append(acc.item())\n",
    "        logs['loss'].append(loss.item())\n",
    "    return logs\n",
    "\n",
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        # todo: your code here\n",
    "        <your code>\n",
    "        # end of code\n",
    "        # у вас должно быть две скалярных переменных: с метрикой (acc) и лоссом (loss)\n",
    "        logs['acc'].append(acc.item())\n",
    "        logs['loss'].append(loss.item())\n",
    "    \n",
    "    return {k: [np.mean(v)] for k, v in logs.items()}\n",
    "\n",
    "\n",
    "def plot_logs(logs):\n",
    "    plt.figure()\n",
    "    plt.plot(logs['acc'], zorder=1)\n",
    "    plt.scatter(logs['steps'], logs['test_acc'], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 10),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "    \n",
    "\n",
    "# история всего обучения\n",
    "logs = defaultdict(list)\n",
    "for epoch in range(3):\n",
    "    train_logs = train(model, opt, train_loader)\n",
    "    \n",
    "    # мерджим историю эпохи к истории обучения\n",
    "    for k, v in train_logs.items():\n",
    "        logs[k].extend(v)\n",
    "        \n",
    "    # метрики с валидации усредняем -- они относятся к одному состоянию весов \n",
    "    # сотояние весов определяется количеством тренировочных шагов\n",
    "    test_logs = test(model, test_loader)\n",
    "    for k, v in test_logs.items():\n",
    "        logs[f'test_{k}'].extend(v)\n",
    "    logs['steps'].append(len(logs['loss']))\n",
    "    \n",
    "    clear_output()\n",
    "    plot_logs(logs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-cKfcm8rY9yU"
   },
   "source": [
    "## Fine Tuning\n",
    "\n",
    "\n",
    "Для многих прикладных задач не существует больших датасетов с хорошей разметкой. \n",
    "Поэтому распространенным приемом является тренировка на похожем, но большом датасете и доучивание сети на целевом.\n",
    "\n",
    "Такой прием называют **Transfer Learning** или **Finetuning**.\n",
    "\n",
    "В сверточных сетях для классификации выделяют две части:\n",
    "- тело сети -- feature extractor, набор сверток и пулингов (convolutions and poolings)\n",
    "- голову -- это MLP (набор полносвязных слоев) после которых делается softmax и получаются вероятности разных классов.\n",
    "\n",
    "\n",
    "Вычислительно простым вариантом finetuning является обучение головы при замороженном feature extractor'е.\n",
    "\n",
    "Нам потребуется [предобученная модель](http://pytorch.org/docs/master/torchvision/datasets.html#torchvision-datasets) и датасет для нашей задачи.\n",
    "\n",
    "Предлагается воспользоваться моделью обученной на Imagenet, а в качестве целевого взять [Imagenette (это небольшое простое подмножество Imagenet)](https://github.com/fastai/imagenette)\n",
    "\n",
    "Архив с картинками доступен на\n",
    "https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
    "\n",
    "**Не запускайте на медленном канале! Весит ~95Mb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7356
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5368,
     "status": "ok",
     "timestamp": 1547408069394,
     "user": {
      "displayName": "Irina Saparina",
      "photoUrl": "https://lh5.googleusercontent.com/-RtDGk7mF0Q4/AAAAAAAAAAI/AAAAAAAAAeo/R2Be9b0dcNE/s64/photo.jpg",
      "userId": "06159875551353272028"
     },
     "user_tz": -180
    },
    "id": "k6YZmiwxY9yW",
    "outputId": "635c3449-a16e-4a57-9abf-df9a75bb6f59"
   },
   "outputs": [],
   "source": [
    "! wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
    "! tar xf imagenette2-160.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В файловой системе должны появиться папки:\n",
    "```bash\n",
    "$ tree --filelimit 10\n",
    "├── imagenette2-160\n",
    "│   ├── train\n",
    "│   │   ├── n01440764 [963 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n02102040 [955 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n02979186 [993 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03000684 [858 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03028079 [941 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03394916 [956 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03417042 [961 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03425413 [931 entries exceeds filelimit, not opening dir]\n",
    "│   │   ├── n03445777 [951 entries exceeds filelimit, not opening dir]\n",
    "│   │   └── n03888257 [960 entries exceeds filelimit, not opening dir]\n",
    "│   └── val\n",
    "│       ├── n01440764 [387 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n02102040 [395 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n02979186 [357 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03000684 [386 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03028079 [409 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03394916 [394 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03417042 [389 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03425413 [419 entries exceeds filelimit, not opening dir]\n",
    "│       ├── n03445777 [399 entries exceeds filelimit, not opening dir]\n",
    "│       └── n03888257 [390 entries exceeds filelimit, not opening dir]\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(160),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(\"./imagenette2-160/train/\", transform=train_transform)\n",
    "test_dataset = ImageFolder(\"./imagenette2-160/val/\", transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.1 балла)** выведите несколько примеров из train_dataset с метками.\n",
    "\n",
    "**NB: Обратите внимание на преобразования, которые мы делаем над картинками и предупреждения, которые выдает `plt.imshow`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<your code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.1 балла)** Модифицируйте модель так, чтобы она выдавала логиты на 10 классов, выберете для обучения только параметры измененного слоя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "# hint: вы можете изучить устройство любого объекта в python пользуясь интерактивностью интерпретатора и методом dir()\n",
    "\n",
    "# Список слоев модели можно получить с помощью обхода\n",
    "# for x in model_ft.named_modules():\n",
    "#    print(x[0], x[1])\n",
    "\n",
    "# TODO: подмените в модели последний слой, чтобы она работала для 10 классов\n",
    "\n",
    "print('Before: ', list(model_ft.named_modules())[-1])\n",
    "<your code>\n",
    "\n",
    "print('After: ', list(model_ft.named_modules())[-1])\n",
    "\n",
    "# TODO: выберите, какие параметры дообучать.\n",
    "# для ускорения работы не забудьте выключить подсчёт градиента для всех необучаемых параметров \n",
    "# например, выключить обучение всех параметров можно при помощи этого кода:\n",
    "for params in model_ft.parameters():\n",
    "    params.requires_grad = False \n",
    "\n",
    "    \n",
    "params_to_train = []\n",
    "<your code>\n",
    "    \n",
    "# TODO: выберите, какие параметры дообучать.\n",
    "# для ускорения работы не забудьте выключить подсчёт градиента для всех необучаемых параметров \n",
    "# например, выключить обучение всех параметров можно при помощи этого кода:\n",
    "# for params in model_ft.parameters():\n",
    "#     params.requires_grad = False \n",
    "\n",
    "optimizer = torch.optim.SGD(params_to_train, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы воспользоваться GPU необходимо перенести модель и тензоры на устройство 'cuda'.\n",
    "Это делается с помощью операции `.to`:\n",
    "```\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "```\n",
    "\n",
    "**Задания:**\n",
    "- **(0.1 балла)** Модифицируйте тренировочный цикл так, чтобы вычисления производились на GPU.\n",
    "- **(0.5 балла)** Проведите несколько экспериментов. В каком случае получается более высокое качество: при обучении всей сети или только последнего слоя? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        \n",
    "        <your code>\n",
    "        # снова должно быть две переменных: acc и loss\n",
    "        logs['acc'].append(acc.item())\n",
    "        logs['loss'].append(loss.item())\n",
    "    return logs\n",
    "\n",
    "def test(model, dataloader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        \n",
    "        <your code>\n",
    "        \n",
    "        logs['acc'].append(acc.item())\n",
    "        logs['loss'].append(loss.item())\n",
    "    \n",
    "    return {k: [np.mean(v)] for k, v in logs.items()}\n",
    "\n",
    "def plot_logs(logs):\n",
    "    plt.figure()\n",
    "    plt.plot(logs['acc'], zorder=1)\n",
    "    plt.scatter(logs['steps'], logs['test_acc'], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.show()\n",
    "\n",
    "logs = defaultdict(list)\n",
    "for epoch in range(3):\n",
    "    train_logs = train(model_ft, optimizer, train_loader)\n",
    "    for k, v in train_logs.items():\n",
    "        logs[k].extend(v)\n",
    "        \n",
    "    test_logs = test(model_ft, test_loader)\n",
    "    for k, v in test_logs.items():\n",
    "        logs[f'test_{k}'].extend(v)\n",
    "    logs['steps'].append(len(logs['loss']))\n",
    "    \n",
    "    clear_output()\n",
    "    plot_logs(logs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL18_seminar2_solved.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
