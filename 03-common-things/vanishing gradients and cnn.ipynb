{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Introduction\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m12sl/dl-hse-2020/blob/master/03-common-things/vanishing%20gradients%20and%20cnn.ipynb)\n",
    "\n",
    "В этой тетрадке мы напишем познакомимся с основными операциями для построения сверточных сетей.\n",
    "\n",
    "**Цели тетрадки**\n",
    "\n",
    "1. Знакомство со свертками и пуллингами\n",
    "1. Попрактиковаться в построении сетей\n",
    "\n",
    "\n",
    "**План работы**\n",
    "\n",
    "1. Поэкспериментировать с затуханием градиентов\n",
    "1. Познакомиться со сверточными сетями и операциями для их построения\n",
    "\n",
    "\n",
    "## (повтор) Материалы по pytorch:\n",
    "\n",
    "+ https://pytorch.org/resources/\n",
    "+ https://pytorch.org/docs/stable/index.html\n",
    "+ ходить по исходникам с помощью IDE\n",
    "+ [Классная статья про pytorch internal](http://blog.ezyang.com/2019/05/pytorch-internals/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install requirements\n",
    "! pip install torchviz torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Если вы пользуетесь Colab, проверьте, что вам доступен GPU (иначе включите в настройках GPU-acceleration)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для экспериментов предлагается снова взять **FashionMNIST**.\n",
    "\n",
    "Мы начнем с моделей на полносвязных слоях, так что нужно преобразовать картинки в вектора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_vector = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda t: t.reshape(-1)),\n",
    "])\n",
    "\n",
    "train_dataset = FashionMNIST(\"./tmp\", train=True, download=True, transform=transform_to_vector)\n",
    "val_dataset = FashionMNIST(\"./tmp\", train=False, download=True, transform=transform_to_vector)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=32)\n",
    "\n",
    "plt.figure(figsize=[6, 6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.title(\"Label: %i\" % train_dataset[i][1])\n",
    "    plt.imshow(train_dataset[i][0].reshape(28, 28), cmap='gray')  # don't forget convert vector to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У pytorch моделей есть множество встроенных хелперов.\n",
    "Например генераторы для обхода параметров: `model.named_parameters()` и `model.parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(7, 11),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(11, 10),\n",
    ")\n",
    "\n",
    "for name, p in model.named_parameters():\n",
    "    print(name, p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.05 балла)** Напишите функцию для подсчета количества обучаемых параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    <your code>\n",
    "    return num\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(7, 11),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(11, 10),\n",
    ")\n",
    "\n",
    "assert count_parameters(model) == 208"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.05 балла)** Напишите функцию для вычисления ($L_2$) норм градиентов на каждый из параметров.\n",
    "\n",
    "**NB: функция должна работать на CPU и на GPU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad_norms(model):\n",
    "    <your code>\n",
    "    return {\"some.weight\": some float}\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(7, 11),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(11, 10),\n",
    ")\n",
    "\n",
    "x = torch.ones(13, 7)\n",
    "loss = model(x).mean()\n",
    "loss.backward()\n",
    "\n",
    "assert get_grad_norms(model).keys() == {\"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\"}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    model.to(device)\n",
    "    x = x.to(device)\n",
    "    loss = model(x).mean()\n",
    "    loss.backward()\n",
    "    assert get_grad_norms(model).keys() == {\"0.weight\", \"0.bias\", \"2.weight\", \"2.bias\"}\n",
    "    print(\"All is fine\")\n",
    "else:\n",
    "    print(\"GPU unchecked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.2 балла)** Допишите тренировочный цикл так, чтобы кроме метрик логгировались и выводились еще и нормы градиентов на тренировочных шагах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def train(model, optimizer, dataloader): \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        <your code here>\n",
    "        \n",
    "        # информацию про нормы градиентов каждого слоя сложите как какой-нибудь \n",
    "        # logs['grad_something']\n",
    "        # у вас должно быть две скалярных переменных: с метрикой и лоссом\n",
    "        logs['acc'].append(acc.item())\n",
    "        logs['loss'].append(loss.item())\n",
    "    return logs\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    logs = defaultdict(list)\n",
    "    for x, y in tqdm(dataloader):\n",
    "        <your code>\n",
    "        # здесь подсчет градиентов не нужен\n",
    "        # у вас должно быть две скалярных переменных: с метрикой и лоссом\n",
    "        logs['acc'].append(acc.item())\n",
    "        logs['loss'].append(loss.item())\n",
    "    \n",
    "    return {k: [np.mean(v)] for k, v in logs.items()}\n",
    "\n",
    "def plot_logs(logs):\n",
    "    clear_output()\n",
    "    plt.figure()\n",
    "    plt.plot(logs['acc'], zorder=1)\n",
    "    plt.scatter(logs['steps'], logs['val_acc'], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    # добавьте отображение градиентов здесь\n",
    "    # для отображения подписей воспользуйтесь label&legend\n",
    "    # plt.plot(..., label=name)\n",
    "    # plt.legend() \n",
    "    <your code>        \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, train_loader, val_loader, epochs=10):\n",
    "    logs = defaultdict(list)\n",
    "    for epoch in range(epochs):\n",
    "        train_logs = train(model, opt, train_loader)\n",
    "        \n",
    "        # вы вольны переписать объединение логов\n",
    "        for k, v in train_logs.items():\n",
    "            logs[k].extend(v)\n",
    "\n",
    "        val_logs = validate(model, val_loader)\n",
    "        for k, v in val_logs.items():\n",
    "            logs[f'val_{k}'].extend(v)\n",
    "        logs['steps'].append(len(logs['loss']))\n",
    "\n",
    "        clear_output()\n",
    "        plot_logs(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.1 балл)** Давайте сравним кривые обучения и нормы градиентов для двух сетей:\n",
    "\n",
    "- densenet из прошлого семинара + sigmoids\n",
    "- densenet + relu\n",
    "\n",
    "**(+дополнительный 0.1 балл)** Можно ли что-то сделать, чтобы заставить densenet_sigmoid обучаться лучше (без изменения функций активаций и BN)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_sigmoid = nn.Sequential(\n",
    "    nn.Linear(784, 40),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(40, 40),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(40, 10),\n",
    "    nn.LogSoftmax(dim=-1),\n",
    ")\n",
    "\n",
    "opt = torch.optim.SGD(densenet_sigmoid.parameters(), lr=0.01)\n",
    "train_model(densenet_sigmoid, opt, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_relu = nn.Sequential(\n",
    "    nn.Linear(784, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 10),\n",
    "    nn.LogSoftmax(dim=-1),\n",
    ")\n",
    "\n",
    "opt = torch.optim.SGD(densenet_relu.parameters(), lr=0.01)\n",
    "train_model(densenet_relu, opt, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing Gradients\n",
    "\n",
    "**(0.2 балла)** Предлагается сделать и проучить глубокую полносвязную сеть (10 линейных слоев, по 20 юнитов в каждом, перемежаемых нелинейностями) в нескольких вариациях:\n",
    "\n",
    "- Densenet + Sigmoid\n",
    "- Densenet + ReLU\n",
    "- DenseResNet + Sigmoid\n",
    "- DenseResNet + ReLU\n",
    "\n",
    "**Hint: Для отображения шумных величин можно воспользоваться оконным сглаживанием**\n",
    "\n",
    "**Hint: Вам может пригодиться логарифмический масштаб по y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = <your code>\n",
    "\n",
    "opt = torch.optim.SGD(deep_model.parameters(), lr=0.01)\n",
    "train_model(deep_model, opt, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте ResNet каким-либо способом.\n",
    "\n",
    "Резнет собран из блоков вида $y = x + F(x)$, где $F$ -- это набор \"обычных\" слоев.\n",
    "\n",
    "**(0.2 балла)** Проведите эксперименты с Dense ResNet ReLU и Dense ResNet Sigmoid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = <your code>\n",
    "\n",
    "opt = torch.optim.SGD(resnet.parameters(), lr=0.01)\n",
    "train_model(resnet, opt, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сверточные сети\n",
    "\n",
    "Мы рассмотрим сверточные сети на примере FashionMNIST.\n",
    "\n",
    "В случае картинок, обычно работают с входными тензорами размера `[batch_size, channels, height, widht]` (такой порядок осей называется channels-first или NCHW).\n",
    "\n",
    "Сверточные сети обычно собираются из последовательности слоев:\n",
    "\n",
    "### Convolution\n",
    "https://pytorch.org/docs/stable/nn.html#convolution-layers\n",
    "\n",
    "По тензору бежит скользящее окно и в нем вычисляется свертка с ядром.\n",
    "Обычно говорят о пространственных размерах сверток, например 1x1 или 3x3  свертки, подразумевая, что ядра имеют размер `[1,1,ch]` или `[3,3,ch]`.\n",
    "\n",
    "Сейчас часто используются чуть более сложные варианты сверток: \n",
    "- dilated (atrous, дырявые), \n",
    "- depth-wise\n",
    "- pointwise\n",
    "- separable\n",
    "- group\n",
    "\n",
    "\n",
    "### Pooling\n",
    "https://pytorch.org/docs/stable/nn.html#pooling-layers\n",
    "\n",
    "Действуют аналогично свертках, но не имеют весов, а в бегущем окне вычисляется какая-нибудь функция, например max или mean.\n",
    "\n",
    "\n",
    "### Global pooling (Adaptive Pooling)\n",
    "https://pytorch.org/docs/stable/nn.html#adaptivemaxpool1d\n",
    "\n",
    "Глобальные пулинги (в pytorch они называются адаптивными) убирают пространственные размерности, превращая `[bs, ch, h, w]` в `[bs, ch, 1, 1]`.\n",
    "\n",
    "\n",
    "\n",
    "### Heads and body\n",
    "\n",
    "Удобно выделять в сверточных сетях две части: полносверточную (body, feature extractor, тушка) и классификатор (head, голова).\n",
    "\n",
    "Классификатор обычно состоит из полносвязных слоев (и где-то может обозначаться как MLP, MLP-head), и требует фиксированного размера тензоров (batch_size может варьироваться, но остальные размерности фиксированы).\n",
    "\n",
    "Полносверточная часть обычно может работать на входах произвольных размеров (не меньше минимального).\n",
    "\n",
    "\n",
    "Чтобы объединить эти две части используют какую-нибудь из операций: **Flatten** или **Global Pooling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1 (0.2 балла)\n",
    "\n",
    "Реализуйте сверточную сеть, *2x(Conv+ReLU+MaxPooling) Conv + Relu + Flatten + (Dense + Relu + Dense)*.\n",
    "\n",
    "Точность на валидации должна быть больше 0.9\n",
    "\n",
    "Количество каналов и размеры фильтров выбирайте по желанию, дефолтный вариант 32-64-128 (3х3).\n",
    "\n",
    "**Hint: Для последовательности слоев без skip-connections удобно пользоваться оберткой `nn.Sequential`.**\n",
    "\n",
    "**NB: это упражнение стоит делать на GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = <your code>\n",
    "# В качестве быстрой проверки корректности попробуем прогнать через сеть тензор нужного размера\n",
    "# [bs, ch, h, w]\n",
    "x = torch.zeros([4, 1, 28, 28])\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь сеть ожидает на вход картинки, так что достаточно просто преобразовать PIL.Image в Torch.Tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# имеет смысл добавить нормирование картинок\n",
    "\n",
    "train_dataset = FashionMNIST(\"./tmp\", train=True, download=True, transform=transform)\n",
    "val_dataset = FashionMNIST(\"./tmp\", train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=32)\n",
    "\n",
    "opt = torch.optim.SGD(cnn.parameters(), lr=0.01)\n",
    "train_model(cnn, opt, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
